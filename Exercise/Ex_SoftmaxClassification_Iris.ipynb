{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax Classification - Iris Data set\n",
    "\n",
    "Softmax Classification의 Exercise를 찾던 중 붓꽃(Iris) 데이터셋을 이용하여 여러 개의 sigmoid 함수를 써서 다변수 classification을 해보는 실험을 찾았다.\n",
    "\n",
    "참고 : <https://alphago.pe.kr/entry/4-TensorFlow%EC%99%80-%EB%86%80%EC%9E%90-Softmax-Classification>\n",
    "\n",
    "아래 실험은 위의 참고 사이트의 실험을 그대로 카피한 소스코드이다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-3901c68bdd88>:25: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/util/tf_should_use.py:189: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Step:     0\tLoss: 1.083\tAcc: 35.00%\n",
      "Step:   100\tLoss: 0.815\tAcc: 69.00%\n",
      "Step:   200\tLoss: 0.765\tAcc: 92.00%\n",
      "Step:   300\tLoss: 0.733\tAcc: 98.00%\n",
      "Step:   400\tLoss: 0.710\tAcc: 99.00%\n",
      "Step:   500\tLoss: 0.693\tAcc: 99.00%\n",
      "Step:   600\tLoss: 0.679\tAcc: 99.00%\n",
      "Step:   700\tLoss: 0.669\tAcc: 99.00%\n",
      "Step:   800\tLoss: 0.660\tAcc: 99.00%\n",
      "Step:   900\tLoss: 0.653\tAcc: 99.00%\n",
      "Step:  1000\tLoss: 0.647\tAcc: 99.00%\n",
      "\n",
      "Accuracy: 92.00%\n",
      "\n",
      "The flower which has [[5.6 2.7 4.2 1.3]] may be versicolor\n",
      "Correct!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "keys = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth']\n",
    "data = pd.read_csv(\"iris.csv\")\n",
    "data = data.drop('caseno', axis=1)\n",
    "\n",
    "species = list(data['Species'].unique())\n",
    "data['class'] = data['Species'].map(lambda x: np.eye(len(species))[species.index(x)])\n",
    "\n",
    "testset = data.sample(50)\n",
    "trainset = data.drop(testset.index)\n",
    "\n",
    "nb_classes = len(species)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None,len(keys)])\n",
    "Y = tf.placeholder(tf.float32, [None,len(species)])\n",
    "\n",
    "W = tf.Variable(tf.zeros([len(keys),len(species)]), name= \"Weight\")\n",
    "b = tf.Variable(tf.zeros([len(species)]), name= \"Bias\")\n",
    "\n",
    "H = tf.nn.softmax(tf.matmul(X, W)+b)\n",
    "\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=H, labels=Y, name=\"Cross_Entropy\"))\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.1).minimize(cross_entropy)\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(H,1),tf.argmax(Y,1)), tf.float32))\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "trainset_class = [y for y in trainset['class'].values]\n",
    "\n",
    "for step in xrange(1001):\n",
    "    \n",
    "    sess.run(optimizer, feed_dict={X: trainset[keys].values,\n",
    "                                  Y: trainset_class})\n",
    "    if step%100 == 0:\n",
    "        loss, acc = sess.run([cross_entropy, accuracy], feed_dict={X: trainset[keys].values,\n",
    "                                  Y: trainset_class})\n",
    "        print \"Step: {:5}\\tLoss: {:.3f}\\tAcc: {:.2%}\".format(step, loss, acc)\n",
    "\n",
    "accu =  sess.run(accuracy, feed_dict={X: testset[keys].values,\n",
    "                                   Y: [y for y in testset['class'].values]})\n",
    "\n",
    "print \"\\nAccuracy: {:.2%}\\n\".format(accu)\n",
    "species = [\"setosa\", \"versicolor\", \"virginica\"]\n",
    "\n",
    "sample = data.sample(1)\n",
    "result = species[np.argmax(sess.run(H, feed_dict = {X: sample[keys].values}))]\n",
    "\n",
    "print \"The flower which has\", sample[keys].values, \"may be\", result\n",
    "\n",
    "if result == sample['Species'].values:\n",
    "    print \"Correct!\"\n",
    "\n",
    "else:\n",
    "    print \"Incorrect!\"\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
