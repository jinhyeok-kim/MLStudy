{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Lab03 : Linear regression의 cost 최소화 TensorFlow 구현\n",
    "\n",
    "## Simplified hypothesis\n",
    "\n",
    "$$H(x) = Wx $$\n",
    "$$cost(W) = \\frac{1}{m}\\sum_{i=1}^m (W(x_i)-y_i)^2 $$\n",
    "\n",
    "H(x) = Wx + b에서 계산의 간편을 위해 + b를 지우고 H(x) = Wx로 식을 구성한다.\n",
    "\n",
    "이렇게 나타면 cost는 W의 함수가 된다. W 값이 바뀌게 되면 cost가 바뀌게 된다.\n",
    "cost를 minmize하자는 것은 cost가 최저가 되는 W값을 찾자는 것이다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = [1, 2, 3]\n",
    "Y = [1, 2, 3]\n",
    "\n",
    "W = tf.placeholder(tf.float32)\n",
    "\n",
    "hypothesis = X * W\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "W_val = []\n",
    "cost_val = []\n",
    "\n",
    "for i in range(-30, 50):\n",
    "    feed_W = i * 0.1\n",
    "    curr_cost, curr_W = sess.run([cost, W], feed_dict={W: feed_W})\n",
    "    W_val.append(curr_W)\n",
    "    cost_val.append(curr_cost)\n",
    "    \n",
    "plt.plot(W_val, cost_val)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent\n",
    "\n",
    "$$cost(W) = \\frac{1}{m}\\sum_{i=1}^m (W(x_i)-y_i)^2 $$\n",
    "\n",
    "미분을 하여 기울기를 구한다.\n",
    "기울기가 +가 될 경우 w값은 - 방향으로 움직여야하고,\n",
    "기울기가 -가 될 경우 w값은 + 방향으로 움직여야한다.\n",
    "\n",
    "다음과 같이 이동을 하게 하려면 W에서 미분을 한 값을 빼주면 된다.\n",
    "\n",
    "$$W := W - \\alpha\\frac{1}{m}\\sum_{i=1}^m (W(x_i)-y_i)x_i$$\n",
    "\n",
    "알파는 학습 rate라고 한다.\n",
    "\n",
    "```python\n",
    "# Minimize: Gradient Descent using derivative:\n",
    "# W -= learning_rate * derivative\n",
    "learning_rate = 0.1\n",
    "gradient = tf.reduce_mean((W*X -Y) * X)\n",
    "descent = W - learning_rate * gradient\n",
    "update = W.assign(desent)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 5.426613, array([-0.07835323], dtype=float32))\n",
      "(1, 1.5435702, array([0.42487824], dtype=float32))\n",
      "(2, 0.43905982, array([0.6932684], dtype=float32))\n",
      "(3, 0.124888174, array([0.8364098], dtype=float32))\n",
      "(4, 0.03552373, array([0.9127519], dtype=float32))\n",
      "(5, 0.010104531, array([0.95346767], dtype=float32))\n",
      "(6, 0.0028741758, array([0.9751828], dtype=float32))\n",
      "(7, 0.0008175464, array([0.98676413], dtype=float32))\n",
      "(8, 0.00023254399, array([0.9929409], dtype=float32))\n",
      "(9, 6.614641e-05, array([0.99623513], dtype=float32))\n",
      "(10, 1.8814217e-05, array([0.9979921], dtype=float32))\n",
      "(11, 5.3511735e-06, array([0.99892914], dtype=float32))\n",
      "(12, 1.5220904e-06, array([0.99942887], dtype=float32))\n",
      "(13, 4.3305428e-07, array([0.99969536], dtype=float32))\n",
      "(14, 1.2316353e-07, array([0.9998375], dtype=float32))\n",
      "(15, 3.502997e-08, array([0.99991333], dtype=float32))\n",
      "(16, 9.983675e-09, array([0.99995375], dtype=float32))\n",
      "(17, 2.8357523e-09, array([0.9999753], dtype=float32))\n",
      "(18, 8.1132256e-10, array([0.9999868], dtype=float32))\n",
      "(19, 2.2917845e-10, array([0.99999297], dtype=float32))\n",
      "(20, 6.535691e-11, array([0.99999624], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x_data = [1, 2, 3]\n",
    "y_data = [1, 2, 3]\n",
    "\n",
    "W = tf.Variable(tf.random_normal([1]), name='weight')\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "hypothesis = X * W\n",
    "\n",
    "# cost/Loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "#Minimize\n",
    "learning_rate = 0.1\n",
    "gradient = tf.reduce_mean((W*X -Y) * X)\n",
    "descent = W - learning_rate * gradient\n",
    "update = W.assign(descent)\n",
    "\n",
    "# Minimize\n",
    "# optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "# train = optimizer.minimize(cost)\n",
    "# 위의 mimizie와 동일한 연산과정을 거친다.\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(21):\n",
    "    # step이 진행될 때마다 update를 실행 \n",
    "    sess.run(update, feed_dict={X: x_data, Y: y_data})\n",
    "    print(step, sess.run(cost, feed_dict={X: x_data, Y: y_data}), sess.run(W))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient descent 확인\n",
    "\n",
    "W=5일 때 Output을 확인한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 5.0)\n",
      "(1, 1.2666664)\n",
      "(2, 1.0177778)\n",
      "(3, 1.0011852)\n",
      "(4, 1.000079)\n",
      "(5, 1.0000052)\n",
      "(6, 1.0000004)\n",
      "(7, 1.0)\n",
      "(8, 1.0)\n",
      "(9, 1.0)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "X = [1, 2, 3]\n",
    "Y = [1, 2, 3]\n",
    "\n",
    "W = tf.Variable(5.0)\n",
    "\n",
    "hypothesis = X * W\n",
    "\n",
    "# cost/Loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "#Minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(10):\n",
    "    print(step, sess.run(W))\n",
    "    sess.run(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, -3.0)\n",
      "(1, 0.7333336)\n",
      "(2, 0.98222226)\n",
      "(3, 0.9988148)\n",
      "(4, 0.99992096)\n",
      "(5, 0.9999947)\n",
      "(6, 0.99999964)\n",
      "(7, 0.99999994)\n",
      "(8, 1.0)\n",
      "(9, 1.0)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "X = [1, 2, 3]\n",
    "Y = [1, 2, 3]\n",
    "\n",
    "W = tf.Variable(-3.0)\n",
    "\n",
    "hypothesis = X * W\n",
    "\n",
    "# cost/Loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "#Minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(10):\n",
    "    print(step, sess.run(W))\n",
    "    sess.run(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: compute_gradient and apply_gradient\n",
    "\n",
    "gradient를 손대고 싶어질 수 있는 경우가 있다.  \n",
    "gradient를 임의로 수정하고자 하는 경우."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, [37.333332, 5.0, [(37.333336, 5.0)]])\n",
      "(1, [33.84889, 4.6266665, [(33.84889, 4.6266665)]])\n",
      "(2, [30.689657, 4.2881775, [(30.689657, 4.2881775)]])\n",
      "(3, [27.825287, 3.9812808, [(27.825287, 3.9812808)]])\n",
      "(4, [25.228262, 3.703028, [(25.228262, 3.703028)]])\n",
      "(5, [22.873621, 3.4507453, [(22.873623, 3.4507453)]])\n",
      "(6, [20.738752, 3.2220092, [(20.73875, 3.2220092)]])\n",
      "(7, [18.803137, 3.0146217, [(18.803137, 3.0146217)]])\n",
      "(8, [17.048176, 2.8265903, [(17.048176, 2.8265903)]])\n",
      "(9, [15.457013, 2.6561086, [(15.457014, 2.6561086)]])\n",
      "(10, [14.014359, 2.5015385, [(14.01436, 2.5015385)]])\n",
      "(11, [12.706352, 2.361395, [(12.706352, 2.361395)]])\n",
      "(12, [11.520427, 2.2343314, [(11.520427, 2.2343314)]])\n",
      "(13, [10.445186, 2.119127, [(10.445185, 2.119127)]])\n",
      "(14, [9.470302, 2.0146751, [(9.470302, 2.0146751)]])\n",
      "(15, [8.586407, 1.9199722, [(8.586407, 1.9199722)]])\n",
      "(16, [7.785009, 1.8341081, [(7.785009, 1.8341081)]])\n",
      "(17, [7.0584083, 1.756258, [(7.0584083, 1.756258)]])\n",
      "(18, [6.399624, 1.685674, [(6.399624, 1.685674)]])\n",
      "(19, [5.8023257, 1.6216778, [(5.8023252, 1.6216778)]])\n",
      "(20, [5.260776, 1.5636545, [(5.260776, 1.5636545)]])\n",
      "(21, [4.7697697, 1.5110468, [(4.7697697, 1.5110468)]])\n",
      "(22, [4.324591, 1.4633491, [(4.324591, 1.4633491)]])\n",
      "(23, [3.9209633, 1.4201032, [(3.9209635, 1.4201032)]])\n",
      "(24, [3.5550067, 1.3808936, [(3.5550067, 1.3808936)]])\n",
      "(25, [3.2232056, 1.3453435, [(3.2232056, 1.3453435)]])\n",
      "(26, [2.9223735, 1.3131114, [(2.9223735, 1.3131114)]])\n",
      "(27, [2.6496189, 1.2838877, [(2.6496186, 1.2838877)]])\n",
      "(28, [2.4023216, 1.2573916, [(2.4023216, 1.2573916)]])\n",
      "(29, [2.178105, 1.2333684, [(2.178105, 1.2333684)]])\n",
      "(30, [1.9748148, 1.2115873, [(1.9748147, 1.2115873)]])\n",
      "(31, [1.7904993, 1.1918392, [(1.7904994, 1.1918392)]])\n",
      "(32, [1.623386, 1.1739342, [(1.6233861, 1.1739342)]])\n",
      "(33, [1.4718695, 1.1577003, [(1.4718695, 1.1577003)]])\n",
      "(34, [1.3344955, 1.1429816, [(1.3344957, 1.1429816)]])\n",
      "(35, [1.2099417, 1.1296366, [(1.2099419, 1.1296366)]])\n",
      "(36, [1.0970144, 1.1175373, [(1.0970144, 1.1175373)]])\n",
      "(37, [0.9946267, 1.1065671, [(0.9946267, 1.1065671)]])\n",
      "(38, [0.90179497, 1.0966209, [(0.901795, 1.0966209)]])\n",
      "(39, [0.8176275, 1.087603, [(0.81762755, 1.087603)]])\n",
      "(40, [0.7413151, 1.0794266, [(0.7413151, 1.0794266)]])\n",
      "(41, [0.67212623, 1.0720135, [(0.67212623, 1.0720135)]])\n",
      "(42, [0.609394, 1.0652922, [(0.609394, 1.0652922)]])\n",
      "(43, [0.5525169, 1.0591983, [(0.5525169, 1.0591983)]])\n",
      "(44, [0.50094914, 1.0536731, [(0.50094914, 1.0536731)]])\n",
      "(45, [0.45419374, 1.0486636, [(0.45419377, 1.0486636)]])\n",
      "(46, [0.41180158, 1.0441216, [(0.41180158, 1.0441216)]])\n",
      "(47, [0.37336722, 1.0400037, [(0.37336725, 1.0400037)]])\n",
      "(48, [0.33851996, 1.03627, [(0.33852, 1.03627)]])\n",
      "(49, [0.30692515, 1.0328848, [(0.30692515, 1.0328848)]])\n",
      "(50, [0.27827826, 1.0298156, [(0.2782783, 1.0298156)]])\n",
      "(51, [0.25230527, 1.0270327, [(0.25230527, 1.0270327)]])\n",
      "(52, [0.2287569, 1.0245097, [(0.2287569, 1.0245097)]])\n",
      "(53, [0.20740573, 1.022222, [(0.20740573, 1.022222)]])\n",
      "(54, [0.18804836, 1.020148, [(0.18804836, 1.020148)]])\n",
      "(55, [0.17049654, 1.0182675, [(0.17049655, 1.0182675)]])\n",
      "(56, [0.15458433, 1.0165626, [(0.15458433, 1.0165626)]])\n",
      "(57, [0.14015675, 1.0150168, [(0.14015675, 1.0150168)]])\n",
      "(58, [0.12707591, 1.0136153, [(0.12707591, 1.0136153)]])\n",
      "(59, [0.11521538, 1.0123445, [(0.11521538, 1.0123445)]])\n",
      "(60, [0.10446167, 1.0111923, [(0.10446167, 1.0111923)]])\n",
      "(61, [0.09471202, 1.0101477, [(0.09471202, 1.0101477)]])\n",
      "(62, [0.08587202, 1.0092006, [(0.08587202, 1.0092006)]])\n",
      "(63, [0.07785805, 1.0083419, [(0.07785805, 1.0083419)]])\n",
      "(64, [0.07059129, 1.0075634, [(0.07059129, 1.0075634)]])\n",
      "(65, [0.06400236, 1.0068574, [(0.06400236, 1.0068574)]])\n",
      "(66, [0.05802846, 1.0062174, [(0.05802846, 1.0062174)]])\n",
      "(67, [0.052612226, 1.005637, [(0.052612226, 1.005637)]])\n",
      "(68, [0.047702473, 1.005111, [(0.047702473, 1.005111)]])\n",
      "(69, [0.043249767, 1.0046339, [(0.043249767, 1.0046339)]])\n",
      "(70, [0.03921318, 1.0042014, [(0.03921318, 1.0042014)]])\n",
      "(71, [0.035553534, 1.0038093, [(0.035553537, 1.0038093)]])\n",
      "(72, [0.032236177, 1.0034539, [(0.03223618, 1.0034539)]])\n",
      "(73, [0.029227654, 1.0031315, [(0.029227655, 1.0031315)]])\n",
      "(74, [0.02649951, 1.0028392, [(0.02649951, 1.0028392)]])\n",
      "(75, [0.024025917, 1.0025742, [(0.024025917, 1.0025742)]])\n",
      "(76, [0.021783749, 1.002334, [(0.02178375, 1.002334)]])\n",
      "(77, [0.01975123, 1.0021162, [(0.019751232, 1.0021162)]])\n",
      "(78, [0.017907381, 1.0019187, [(0.017907381, 1.0019187)]])\n",
      "(79, [0.016236702, 1.0017396, [(0.016236704, 1.0017396)]])\n",
      "(80, [0.014720838, 1.0015773, [(0.014720838, 1.0015773)]])\n",
      "(81, [0.01334699, 1.00143, [(0.013346991, 1.00143)]])\n",
      "(82, [0.012100856, 1.0012965, [(0.012100856, 1.0012965)]])\n",
      "(83, [0.010971785, 1.0011755, [(0.010971785, 1.0011755)]])\n",
      "(84, [0.0099481745, 1.0010659, [(0.0099481745, 1.0010659)]])\n",
      "(85, [0.009018898, 1.0009663, [(0.009018898, 1.0009663)]])\n",
      "(86, [0.008176883, 1.0008761, [(0.008176884, 1.0008761)]])\n",
      "(87, [0.007413149, 1.0007943, [(0.007413149, 1.0007943)]])\n",
      "(88, [0.006721576, 1.0007201, [(0.006721576, 1.0007201)]])\n",
      "(89, [0.0060940585, 1.0006529, [(0.0060940585, 1.0006529)]])\n",
      "(90, [0.005525271, 1.000592, [(0.0055252714, 1.000592)]])\n",
      "(91, [0.0050098896, 1.0005368, [(0.0050098896, 1.0005368)]])\n",
      "(92, [0.004542589, 1.0004867, [(0.004542589, 1.0004867)]])\n",
      "(93, [0.0041189194, 1.0004413, [(0.0041189194, 1.0004413)]])\n",
      "(94, [0.0037339528, 1.0004001, [(0.003733953, 1.0004001)]])\n",
      "(95, [0.0033854644, 1.0003628, [(0.0033854644, 1.0003628)]])\n",
      "(96, [0.0030694802, 1.0003289, [(0.0030694804, 1.0003289)]])\n",
      "(97, [0.0027837753, 1.0002983, [(0.0027837753, 1.0002983)]])\n",
      "(98, [0.0025234222, 1.0002704, [(0.0025234222, 1.0002704)]])\n",
      "(99, [0.0022875469, 1.0002451, [(0.0022875469, 1.0002451)]])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "X = [1, 2, 3]\n",
    "Y = [1, 2, 3]\n",
    "\n",
    "W = tf.Variable(5.)\n",
    "\n",
    "hypothesis = X * W\n",
    "\n",
    "gradient = tf.reduce_mean((W*X -Y) * X) * 2\n",
    "\n",
    "# cost/Loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "#Minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "#바로 minimize를 하라고 하지않고 gradient 계산 값을 달라고 한다.\n",
    "gvs = optimizer.compute_gradients(cost,[W])\n",
    "\n",
    "#이 사이에 gvs를 가공하여 gradient를 변경\n",
    "\n",
    "apply_gradients = optimizer.apply_gradients(gvs)\n",
    "\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "#자동으로 계산된 gradient와 수식으로 계산한 gradient가 같은 값인지 확인해보자\n",
    "for step in range(100):\n",
    "    print(step, sess.run([gradient, W, gvs]))\n",
    "    sess.run(apply_gradients)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
