{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Lab09-2: Tensorboard (Neural Net for XOR)\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "#1. From TF graph, decide which tensors you want to log\n",
    "w2_hist = tf.summary.histogram(\"weight2\", W2)\n",
    "cost_summ = tf.summary.scalar(\"cost\", cost)\n",
    "\n",
    "#2. Merge all summaries\n",
    "summary = tf.summary.merge_all()\n",
    "\n",
    "#3. Create writer and add graph\n",
    "writer = tf.summary.FileWriter('./logs')\n",
    "writer.add_graph(sess.graph)\n",
    "\n",
    "#4. Run summary merge and add_summary\n",
    "s, _ = sess.run([summary, optimizer], feed_dict=feed_dict)\n",
    "writer.add_summary(s, global_step=global_step)\n",
    "\n",
    "#5. Launch TensorBoard\n",
    "tensorboard --logidr=./logs\n",
    "\n",
    "```\n",
    "\n",
    "## 1. From TF graph, decide which tensors you want to log\n",
    "\n",
    "### Scalar tensors\n",
    "\n",
    "```python\n",
    "\n",
    "cost_Sum = tf.summary.scalar(\"cost\", cost)\n",
    "\n",
    "```\n",
    "\n",
    "### Histogram (multi-dimensional tensors)\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([2, 1]), name = 'weight2')\n",
    "b2 = tf.Variable(tf.random_normal([1]), name = 'bias2')\n",
    "\n",
    "hypothesis = tf.sigmoid(tf.matmul(layer1, W2) + b2)\n",
    "\n",
    "w2_hist = tf.summary.histogram(\"weights2\", W2)\n",
    "b2_hist = tf.summary.histogram(\"biases2\", b2)\n",
    "hypothesis_his = tf.summary.histogram(\"hypothesis\", hypothesis)\n",
    "\n",
    "```\n",
    "\n",
    "### Add scope for better graph hierarchy\n",
    "\n",
    "```python\n",
    "\n",
    "with tf.name_scope(\"layer1\") as scope:\n",
    "    W1 = tf.Variable(tf.random_normal([2, 2]), name = 'weight1')\n",
    "    b1 = tf.Variable(tf.random_normal([2]), name = 'bias1')\n",
    "    hypothesis = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "\n",
    "    w1_hist = tf.summary.histogram(\"weights2\", W2)\n",
    "    b1_hist = tf.summary.histogram(\"biases2\", b2)\n",
    "    layer1_his = tf.summary.histogram(\"layer1\", layer1)\n",
    "\n",
    "    \n",
    "with tf.name_scope(\"layer2\") as scope:\n",
    "    W2 = tf.Variable(tf.random_normal([2, 1]), name = 'weight2')\n",
    "    b2 = tf.Variable(tf.random_normal([1]), name = 'bias2')\n",
    "    hypothesis = tf.sigmoid(tf.matmul(layer1, W2) + b2)\n",
    "\n",
    "    w2_hist = tf.summary.histogram(\"weights2\", W2)\n",
    "    b2_hist = tf.summary.histogram(\"biases2\", b2)\n",
    "    hypothesis_his = tf.summary.histogram(\"hypothesis\", hypothesis)\n",
    "```\n",
    "\n",
    "\n",
    "## 2. Merge summaries and create writer\n",
    "## 3. after creating session\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "#2. Merge all summaries\n",
    "summary = tf.summary.merge_all()\n",
    "\n",
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "#3. Create summary wirter\n",
    "writer = tf.summary.FileWriter(TB_SUMMARY_DIR)\n",
    "writer.add_graph(sess.graph)\n",
    "\n",
    "```\n",
    "\n",
    "## 4. Run merged summary and write( add summary)\n",
    "\n",
    "```python\n",
    "\n",
    "#4. Run summary merge and add_summary\n",
    "s, _ = sess.run([summary, optimizer], feed_dict=feed_dict)\n",
    "writer.add_summary(s, global_step=global_step)\n",
    "global_step += 1\n",
    "\n",
    "```\n",
    "\n",
    "## 5.Launch tensorboard (local)\n",
    "\n",
    "```python\n",
    "\n",
    "writer = tf.summary.FileWriter(\"./logs/xor_logs\")\n",
    "\n",
    "# tensorboard -logdir=./logs/xor_logs\n",
    "\n",
    "```\n",
    "\n",
    "## 5-1.Launch tensorboard (remote server)\n",
    "\n",
    "```shell\n",
    "\n",
    "ssh - L local_port:127.0.0.1:remote_port username@server.com\n",
    "\n",
    "tensorboard -logdir=./logs/xor_logs\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "## Multiple runs\n",
    "\n",
    "```python\n",
    "\n",
    "#tensorboard -logdir=./logs/xor_logs\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "writer = tf.summary.FileWriter(\"\"./logs/xor_logs\"\")\n",
    "\n",
    "#tensorboard -logdir=./logs/xor_logs_r0_01\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "writer = tf.summary.FileWriter(\"\"./logs/xor_logs_r0_01\"\")\n",
    "\n",
    "#tensorboard -logdir=./logs\n",
    "\n",
    "```\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
