{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Lab07-1 : Learning rate, Evaluation\n",
    "\n",
    "## Training and Test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-b2d61f12a706>:28: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `argmax` instead\n",
      "0 7.837591 [[ 1.1419189  -0.49156463  1.439095  ]\n",
      " [-0.7672531   0.17333063 -1.0920527 ]\n",
      " [-1.0635648   1.2491653   1.8695364 ]]\n",
      "20 1.0615451 [[ 1.1210476  -0.55201083  1.5204127 ]\n",
      " [ 0.05190028 -0.54985064 -1.1880246 ]\n",
      " [ 0.16761729  0.95104367  0.93647623]]\n",
      "40 0.86181664 [[ 0.9376013  -0.5342438   1.6860919 ]\n",
      " [-0.12559101 -0.61840737 -0.9419768 ]\n",
      " [ 0.4238496   1.0008209   0.6304668 ]]\n",
      "60 0.7695284 [[ 0.7921984  -0.5243351   1.8215863 ]\n",
      " [-0.24149196 -0.6344022  -0.8100809 ]\n",
      " [ 0.60226506  1.0105876   0.4422847 ]]\n",
      "80 0.7189379 [[ 0.66637707 -0.5151936   1.9382663 ]\n",
      " [-0.31224304 -0.63285124 -0.7408808 ]\n",
      " [ 0.72573704  1.0073546   0.3220456 ]]\n",
      "100 0.6856191 [[ 0.55196553 -0.5049175   2.0424016 ]\n",
      " [-0.35341468 -0.62749135 -0.70506895]\n",
      " [ 0.8136185   1.0012883   0.2402307 ]]\n",
      "120 0.66049093 [[ 0.44553772 -0.49341014  2.1373224 ]\n",
      " [-0.3765802  -0.6219276  -0.6874671 ]\n",
      " [ 0.8794393   0.99491894  0.18077931]]\n",
      "140 0.63990474 [[ 0.34542066 -0.48097536  2.2250047 ]\n",
      " [-0.3892607  -0.6167508  -0.6799636 ]\n",
      " [ 0.9317545   0.98860544  0.13477752]]\n",
      "160 0.6222262 [[ 0.25059327 -0.46791     2.3067663 ]\n",
      " [-0.39599478 -0.61192125 -0.67805904]\n",
      " [ 0.9757135   0.98230726  0.09711674]]\n",
      "180 0.60661805 [[ 0.16031629 -0.454432    2.3835654 ]\n",
      " [-0.3994215  -0.6073584  -0.67919517]\n",
      " [ 1.014363    0.9759893   0.06478533]]\n",
      "200 0.59259063 [[ 0.07400581 -0.440692    2.4561362 ]\n",
      " [-0.4010499  -0.6030253  -0.6818997 ]\n",
      " [ 1.0495079   0.9696628   0.03596715]]\n",
      "Prediction: [2 2 2]\n",
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x_data = [[1, 2, 1], [1, 3, 2], [1, 3, 4], [1, 5, 5],\n",
    "          [1, 7, 5], [1, 2, 5], [1, 6, 6], [1, 7, 7]]\n",
    "y_data = [[0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 1, 0],\n",
    "          [0, 1, 0], [0, 1, 0], [1, 0, 0], [1, 0, 0]]\n",
    "\n",
    "# Evaluation our model using this test dataset\n",
    "x_test = [[2, 1, 1], [3, 1, 2], [3, 3, 4]]\n",
    "y_test = [[0, 0, 1], [0, 0, 1], [0, 0, 1]]\n",
    "\n",
    "X = tf.placeholder(\"float\", [None, 3])\n",
    "Y = tf.placeholder(\"float\", [None, 3])\n",
    "W = tf.Variable(tf.random_normal([3,3]))\n",
    "b = tf.Variable(tf.random_normal([3]))\n",
    "\n",
    "# tf.nn.softmax compute softmax activations\n",
    "# softmax = exp(Logistic) / reduce_sum(exp(Logits), dim)\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X, W) + b)\n",
    "\n",
    "# Cross entropy cost/Loss\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), axis=1))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "\n",
    "# ------------ 위의 소스 코드까지가 graph ----------------------\n",
    "\n",
    "prediction = tf.arg_max(hypothesis, 1)\n",
    "is_correct = tf.equal(prediction, tf.arg_max(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "# Launch graph\n",
    "with tf.Session() as sess:\n",
    "    #initailize\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(201):\n",
    "        cost_val, W_val, _ = sess.run([cost, W, optimizer],\n",
    "                                     feed_dict={X: x_data, Y: y_data})\n",
    "        if step % 20 == 0:\n",
    "            print step, cost_val, W_val \n",
    "\n",
    "    # predict\n",
    "    print \"Prediction:\", sess.run(prediction, feed_dict={X: x_test})\n",
    "    # Calculate the accuracy\n",
    "    print \"Accuracy: \", sess.run(accuracy, feed_dict={X: x_test, Y: y_test})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Big learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 8.203156 [[ 0.42684644 -1.4663756  -0.08077377]\n",
      " [ 2.193118   -1.856834    3.1821587 ]\n",
      " [ 0.69007254 -2.310068    0.9290008 ]]\n",
      "20 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "40 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "60 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "80 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "100 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "120 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "140 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "160 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "180 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "200 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "Prediction: [0 0 0]\n",
      "Accuracy:  0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x_data = [[1, 2, 1], [1, 3, 2], [1, 3, 4], [1, 5, 5],\n",
    "          [1, 7, 5], [1, 2, 5], [1, 6, 6], [1, 7, 7]]\n",
    "y_data = [[0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 1, 0],\n",
    "          [0, 1, 0], [0, 1, 0], [1, 0, 0], [1, 0, 0]]\n",
    "\n",
    "# Evaluation our model using this test dataset\n",
    "x_test = [[2, 1, 1], [3, 1, 2], [3, 3, 4]]\n",
    "y_test = [[0, 0, 1], [0, 0, 1], [0, 0, 1]]\n",
    "\n",
    "X = tf.placeholder(\"float\", [None, 3])\n",
    "Y = tf.placeholder(\"float\", [None, 3])\n",
    "W = tf.Variable(tf.random_normal([3,3]))\n",
    "b = tf.Variable(tf.random_normal([3]))\n",
    "\n",
    "# tf.nn.softmax compute softmax activations\n",
    "# softmax = exp(Logistic) / reduce_sum(exp(Logits), dim)\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X, W) + b)\n",
    "\n",
    "# Cross entropy cost/Loss\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), axis=1))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1.5).minimize(cost)\n",
    "\n",
    "\n",
    "# ------------ 위의 소스 코드까지가 graph ----------------------\n",
    "\n",
    "prediction = tf.arg_max(hypothesis, 1)\n",
    "is_correct = tf.equal(prediction, tf.arg_max(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "# Launch graph\n",
    "with tf.Session() as sess:\n",
    "    #initailize\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(201):\n",
    "        cost_val, W_val, _ = sess.run([cost, W, optimizer],\n",
    "                                     feed_dict={X: x_data, Y: y_data})\n",
    "        if step % 20 == 0:\n",
    "            print step, cost_val, W_val \n",
    "\n",
    "    # predict\n",
    "    print \"Prediction:\", sess.run(prediction, feed_dict={X: x_test})\n",
    "    # Calculate the accuracy\n",
    "    print \"Accuracy: \", sess.run(accuracy, feed_dict={X: x_test, Y: y_test})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.2304935 [[ 0.4426145   1.4135212  -0.46055332]\n",
      " [-0.39649576  0.50344855 -1.4779618 ]\n",
      " [-0.636693   -1.8015283  -0.40372345]]\n",
      "20 2.2304935 [[ 0.4426145   1.4135212  -0.46055332]\n",
      " [-0.39649576  0.50344855 -1.4779618 ]\n",
      " [-0.636693   -1.8015283  -0.40372345]]\n",
      "40 2.2304935 [[ 0.4426145   1.4135212  -0.46055332]\n",
      " [-0.39649576  0.50344855 -1.4779618 ]\n",
      " [-0.636693   -1.8015283  -0.40372345]]\n",
      "60 2.2304935 [[ 0.4426145   1.4135212  -0.46055332]\n",
      " [-0.39649576  0.50344855 -1.4779618 ]\n",
      " [-0.636693   -1.8015283  -0.40372345]]\n",
      "80 2.2304935 [[ 0.4426145   1.4135212  -0.46055332]\n",
      " [-0.39649576  0.50344855 -1.4779618 ]\n",
      " [-0.636693   -1.8015283  -0.40372345]]\n",
      "100 2.2304935 [[ 0.4426145   1.4135212  -0.46055332]\n",
      " [-0.39649576  0.50344855 -1.4779618 ]\n",
      " [-0.636693   -1.8015283  -0.40372345]]\n",
      "120 2.2304935 [[ 0.4426145   1.4135212  -0.46055332]\n",
      " [-0.39649576  0.50344855 -1.4779618 ]\n",
      " [-0.636693   -1.8015283  -0.40372345]]\n",
      "140 2.2304935 [[ 0.4426145   1.4135212  -0.46055332]\n",
      " [-0.39649576  0.50344855 -1.4779618 ]\n",
      " [-0.636693   -1.8015283  -0.40372345]]\n",
      "160 2.2304935 [[ 0.4426145   1.4135212  -0.46055332]\n",
      " [-0.39649576  0.50344855 -1.4779618 ]\n",
      " [-0.636693   -1.8015283  -0.40372345]]\n",
      "180 2.2304935 [[ 0.4426145   1.4135212  -0.46055332]\n",
      " [-0.39649576  0.50344855 -1.4779618 ]\n",
      " [-0.636693   -1.8015283  -0.40372345]]\n",
      "200 2.2304935 [[ 0.4426145   1.4135212  -0.46055332]\n",
      " [-0.39649576  0.50344855 -1.4779618 ]\n",
      " [-0.636693   -1.8015283  -0.40372345]]\n",
      "Prediction: [1 1 0]\n",
      "Accuracy:  0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x_data = [[1, 2, 1], [1, 3, 2], [1, 3, 4], [1, 5, 5],\n",
    "          [1, 7, 5], [1, 2, 5], [1, 6, 6], [1, 7, 7]]\n",
    "y_data = [[0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 1, 0],\n",
    "          [0, 1, 0], [0, 1, 0], [1, 0, 0], [1, 0, 0]]\n",
    "\n",
    "# Evaluation our model using this test dataset\n",
    "x_test = [[2, 1, 1], [3, 1, 2], [3, 3, 4]]\n",
    "y_test = [[0, 0, 1], [0, 0, 1], [0, 0, 1]]\n",
    "\n",
    "X = tf.placeholder(\"float\", [None, 3])\n",
    "Y = tf.placeholder(\"float\", [None, 3])\n",
    "W = tf.Variable(tf.random_normal([3,3]))\n",
    "b = tf.Variable(tf.random_normal([3]))\n",
    "\n",
    "# tf.nn.softmax compute softmax activations\n",
    "# softmax = exp(Logistic) / reduce_sum(exp(Logits), dim)\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X, W) + b)\n",
    "\n",
    "# Cross entropy cost/Loss\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), axis=1))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-10).minimize(cost)\n",
    "\n",
    "\n",
    "# ------------ 위의 소스 코드까지가 graph ----------------------\n",
    "\n",
    "prediction = tf.arg_max(hypothesis, 1)\n",
    "is_correct = tf.equal(prediction, tf.arg_max(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "# Launch graph\n",
    "with tf.Session() as sess:\n",
    "    #initailize\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(201):\n",
    "        cost_val, W_val, _ = sess.run([cost, W, optimizer],\n",
    "                                     feed_dict={X: x_data, Y: y_data})\n",
    "        if step % 20 == 0:\n",
    "            print step, cost_val, W_val \n",
    "\n",
    "    # predict\n",
    "    print \"Prediction:\", sess.run(prediction, feed_dict={X: x_test})\n",
    "    # Calculate the accuracy\n",
    "    print \"Accuracy: \", sess.run(accuracy, feed_dict={X: x_test, Y: y_test})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-normalized inputs\n",
    "\n",
    "```\n",
    "xy = np.array([[828.659973, 833.450012, 908100, 828.349976, 831.659973],\n",
    "               [823.02002, 828.070007, 1828100, 821.655029, 828.070007],\n",
    "               [819.929993, 824.400024, 1438100, 818.97998, 824.159973],\n",
    "               [816, 820.958984, 1008100, 815.48999, 819.23999],\n",
    "               [819.359985, 823, 1188100, 818.469971, 818.97998],\n",
    "               [819, 823, 1198100, 816, 820.450012],\n",
    "               [811.700012, 815.25, 1098100, 809.780029, 813.669983],\n",
    "               [809.51001, 816.659973, 1398100, 804.539978, 809.559998]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Cost:  598648800000.0 \n",
      "Prediction:\n",
      "[[ -545071.75]\n",
      " [-1097737.5 ]\n",
      " [ -863458.25]\n",
      " [ -605150.56]\n",
      " [ -713278.75]\n",
      " [ -719287.6 ]\n",
      " [ -659218.8 ]\n",
      " [ -839437.8 ]]\n",
      "1 Cost:  6.5772375e+26 \n",
      "Prediction:\n",
      "[[1.8090604e+13]\n",
      " [3.6418240e+13]\n",
      " [2.8648917e+13]\n",
      " [2.0082739e+13]\n",
      " [2.3668581e+13]\n",
      " [2.3867794e+13]\n",
      " [2.1875659e+13]\n",
      " [2.7852062e+13]]\n",
      "2 Cost:  inf \n",
      "Prediction:\n",
      "[[-5.9963747e+20]\n",
      " [-1.2071316e+21]\n",
      " [-9.4960699e+20]\n",
      " [-6.6566946e+20]\n",
      " [-7.8452706e+20]\n",
      " [-7.9113025e+20]\n",
      " [-7.2509826e+20]\n",
      " [-9.2319415e+20]]\n",
      "3 Cost:  inf \n",
      "Prediction:\n",
      "[[1.9875796e+28]\n",
      " [4.0012011e+28]\n",
      " [3.1476008e+28]\n",
      " [2.2064514e+28]\n",
      " [2.6004209e+28]\n",
      " [2.6223081e+28]\n",
      " [2.4034361e+28]\n",
      " [3.0600519e+28]]\n",
      "4 Cost:  inf \n",
      "Prediction:\n",
      "[[-6.5881006e+35]\n",
      " [-1.3262522e+36]\n",
      " [-1.0433148e+36]\n",
      " [-7.3135810e+35]\n",
      " [-8.6194465e+35]\n",
      " [-8.6919942e+35]\n",
      " [-7.9665138e+35]\n",
      " [-1.0142956e+36]]\n",
      "5 Cost:  inf \n",
      "Prediction:\n",
      "[[inf]\n",
      " [inf]\n",
      " [inf]\n",
      " [inf]\n",
      " [inf]\n",
      " [inf]\n",
      " [inf]\n",
      " [inf]]\n",
      "6 Cost:  nan \n",
      "Prediction:\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "7 Cost:  nan \n",
      "Prediction:\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "8 Cost:  nan \n",
      "Prediction:\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "9 Cost:  nan \n",
      "Prediction:\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "10 Cost:  nan \n",
      "Prediction:\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "xy = np.array([[828.659973, 833.450012, 908100, 828.349976, 831.659973],\n",
    "               [823.02002, 828.070007, 1828100, 821.655029, 828.070007],\n",
    "               [819.929993, 824.400024, 1438100, 818.97998, 824.159973],\n",
    "               [816, 820.958984, 1008100, 815.48999, 819.23999],\n",
    "               [819.359985, 823, 1188100, 818.469971, 818.97998],\n",
    "               [819, 823, 1198100, 816, 820.450012],\n",
    "               [811.700012, 815.25, 1098100, 809.780029, 813.669983],\n",
    "               [809.51001, 816.659973, 1398100, 804.539978, 809.559998]])\n",
    "\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]\n",
    "\n",
    "# Evaluation our model using this test dataset\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 4])\n",
    "Y = tf.placeholder(tf.float32, [None, 1])\n",
    "W = tf.Variable(tf.random_normal([4,1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# Cross entropy cost/Loss\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# ------------ 위의 소스 코드까지가 graph ----------------------\n",
    "\n",
    "# Launch graph\n",
    "with tf.Session() as sess:\n",
    "    #initailize\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(11):\n",
    "        cost_val, hy_val, _ = sess.run([cost, hypothesis, train],\n",
    "                                     feed_dict={X: x_data, Y: y_data})\n",
    "        print step, \"Cost: \", cost_val, \"\\nPrediction:\\n\", hy_val "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalized inputs (min-max scale\n",
    "\n",
    "```\n",
    "xy = MinMaxScaler(xy)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99999999 0.99999999 0.         1.         1.        ]\n",
      " [0.70548491 0.70439552 1.         0.71881782 0.83755791]\n",
      " [0.54412549 0.50274824 0.57608696 0.606468   0.6606331 ]\n",
      " [0.33890353 0.31368023 0.10869565 0.45989134 0.43800918]\n",
      " [0.51436    0.42582389 0.30434783 0.58504805 0.42624401]\n",
      " [0.49556179 0.42582389 0.31521739 0.48131134 0.49276137]\n",
      " [0.11436064 0.         0.20652174 0.22007776 0.18597238]\n",
      " [0.         0.07747099 0.5326087  0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def MinMaxScaler(data):\n",
    "\n",
    "    numerator = data - np.min(data, 0)\n",
    "\n",
    "    denominator = np.max(data, 0) - np.min(data, 0)\n",
    "\n",
    "    # noise term prevents the zero division\n",
    "\n",
    "    return numerator / (denominator + 1e-7)\n",
    "\n",
    "xy = np.array([[828.659973, 833.450012, 908100, 828.349976, 831.659973],\n",
    "               [823.02002, 828.070007, 1828100, 821.655029, 828.070007],\n",
    "               [819.929993, 824.400024, 1438100, 818.97998, 824.159973],\n",
    "               [816, 820.958984, 1008100, 815.48999, 819.23999],\n",
    "               [819.359985, 823, 1188100, 818.469971, 818.97998],\n",
    "               [819, 823, 1198100, 816, 820.450012],\n",
    "               [811.700012, 815.25, 1098100, 809.780029, 813.669983],\n",
    "               [809.51001, 816.659973, 1398100, 804.539978, 809.559998]])\n",
    "\n",
    "xy = MinMaxScaler(xy)\n",
    "\n",
    "print xy\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Cost:  0.010124576 \n",
      "Prediction:\n",
      "[[1.1515926 ]\n",
      " [0.8121542 ]\n",
      " [0.60433173]\n",
      " [0.36825824]\n",
      " [0.55450696]\n",
      " [0.5970996 ]\n",
      " [0.10448615]\n",
      " [0.12392762]]\n",
      "1000 Cost:  0.010014865 \n",
      "Prediction:\n",
      "[[1.1495475 ]\n",
      " [0.81037384]\n",
      " [0.6028282 ]\n",
      " [0.36706638]\n",
      " [0.5530996 ]\n",
      " [0.59574294]\n",
      " [0.10363788]\n",
      " [0.12314511]]\n",
      "2000 Cost:  0.009911973 \n",
      "Prediction:\n",
      "[[1.14755   ]\n",
      " [0.8086455 ]\n",
      " [0.60136795]\n",
      " [0.36590913]\n",
      " [0.55173117]\n",
      " [0.5944254 ]\n",
      " [0.10281877]\n",
      " [0.12239674]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def MinMaxScaler(data):\n",
    "\n",
    "    numerator = data - np.min(data, 0)\n",
    "\n",
    "    denominator = np.max(data, 0) - np.min(data, 0)\n",
    "\n",
    "    # noise term prevents the zero division\n",
    "\n",
    "    return numerator / (denominator + 1e-7)\n",
    "\n",
    "xy = np.array([[828.659973, 833.450012, 908100, 828.349976, 831.659973],\n",
    "               [823.02002, 828.070007, 1828100, 821.655029, 828.070007],\n",
    "               [819.929993, 824.400024, 1438100, 818.97998, 824.159973],\n",
    "               [816, 820.958984, 1008100, 815.48999, 819.23999],\n",
    "               [819.359985, 823, 1188100, 818.469971, 818.97998],\n",
    "               [819, 823, 1198100, 816, 820.450012],\n",
    "               [811.700012, 815.25, 1098100, 809.780029, 813.669983],\n",
    "               [809.51001, 816.659973, 1398100, 804.539978, 809.559998]])\n",
    "\n",
    "xy = MinMaxScaler(xy)\n",
    "\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]\n",
    "\n",
    "# Evaluation our model using this test dataset\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 4])\n",
    "Y = tf.placeholder(tf.float32, [None, 1])\n",
    "W = tf.Variable(tf.random_normal([4,1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# Cross entropy cost/Loss\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# ------------ 위의 소스 코드까지가 graph ----------------------\n",
    "\n",
    "# Launch graph\n",
    "with tf.Session() as sess:\n",
    "    #initailize\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(2001):\n",
    "        cost_val, hy_val, _ = sess.run([cost, hypothesis, train],\n",
    "                                     feed_dict={X: x_data, Y: y_data})\n",
    "        if step % 1000 == 0:\n",
    "            print step, \"Cost: \", cost_val, \"\\nPrediction:\\n\", hy_val "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
