{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Lab07-2 : Meet MNIST Datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Epch:0001 cost =  2.709861920\n",
      "Epch:0002 cost =  1.142232756\n",
      "Epch:0003 cost =  0.910223033\n",
      "Epch:0004 cost =  0.793498486\n",
      "Epch:0005 cost =  0.718433119\n",
      "Epch:0006 cost =  0.665098684\n",
      "Epch:0007 cost =  0.624866126\n",
      "Epch:0008 cost =  0.592659530\n",
      "Epch:0009 cost =  0.567058191\n",
      "Epch:0010 cost =  0.545026293\n",
      "Epch:0011 cost =  0.526715620\n",
      "Epch:0012 cost =  0.510526478\n",
      "Epch:0013 cost =  0.496533751\n",
      "Epch:0014 cost =  0.484279632\n",
      "Epch:0015 cost =  0.472980749\n",
      "Accuracy:  0.8904\n",
      "Label: [1]\n",
      "Prediction: [1]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "# check out https://www.tensorflow.org/get_started/mnist/beginnners for\n",
    "# more information about the mnist dataset\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "nb_classes = 10\n",
    "\n",
    "# MNIST data image of shape 28*28 = 784\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "# 0 - 9 digits recognition = 10 nb_classes\n",
    "Y = tf.placeholder(tf.float32, [None, nb_classes])\n",
    "\n",
    "\n",
    "W = tf.Variable(tf.random_normal([784, nb_classes]))\n",
    "b = tf.Variable(tf.random_normal([nb_classes]))\n",
    "\n",
    "# Softmax!!\n",
    "\n",
    "# tf.nn.softmax compute softmax activations\n",
    "# softmax = exp(Logistic) / reduce_sum(exp(Logits), dim)\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X, W) + b)\n",
    "\n",
    "# Cross entropy cost/Loss\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), axis=1))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "# ------------ 위의 소스 코드까지가 graph ----------------------\n",
    "\n",
    "\n",
    "# Test model\n",
    "prediction = tf.arg_max(hypothesis, 1)\n",
    "is_correct = tf.equal(prediction, tf.arg_max(Y, 1))\n",
    "# Calculate accuracy\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "# Training epoch/batch\n",
    "# epoch(에폭) : 전체 dataset을 한 번 다 학습 시키는 것을 1 epoch이라고 한다.\n",
    "# batch size : 1 epoch을 하려고 하는데 dataset이 너무 큰 경우 잘라서 넣어줘야하는데 그 자르는 size를 batch size라고 한다.\n",
    "\n",
    "# Example : TrainingSet이 1000개가 있고 batch size가 500인 경우, 2 iteration 하면 1 epoch이 된다.\n",
    " \n",
    "# parameters\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs): # dataset을 training_epoch번 학습할꺼야\n",
    "        avg_cost = 0\n",
    "        total_batch = int(mnist.train.num_examples / batch_size) # 전체 data set을 batch_size로 나눈 번만큼 학습을 해야 1 epoch을 학습 가능\n",
    "        \n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            c, _ = sess.run([cost, optimizer], feed_dict={X: batch_xs, Y: batch_ys})\n",
    "            avg_cost += c / total_batch\n",
    "            \n",
    "        print 'Epch:' '%04d' % (epoch + 1), 'cost = ', '{:.9f}'.format(avg_cost)\n",
    "\n",
    "\n",
    "    # Test the model using test sets\n",
    "    print \"Accuracy: \", accuracy.eval(session=sess,\n",
    "                                 feed_dict={X: mnist.test.images, Y: mnist.test.labels})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Get one and predict\n",
    "    r = random.randint(0, mnist.test.num_examples - 1)\n",
    "    print \"Label:\", sess.run(tf.argmax(mnist.test.labels[r:r+1], 1))\n",
    "    print \"Prediction:\", sess.run(tf.argmax(hypothesis, 1),\n",
    "                                 feed_dict={X: mnist.test.images[r:r + 1]})\n",
    "\n",
    "    plt.imshow(mnist.test.images[r:r + 1].\n",
    "              reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
